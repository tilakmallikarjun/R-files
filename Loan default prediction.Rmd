---
title: "ML loan efault prediction"
author: "P M Tilak"
output: word_document
---
##Problem Statement: 
The data set describing borrower's credentials is to be analyzed to predict the default rate so as to decide whether to grant the loan or not for a  new applicant.

##Libraries Required:
```{r , library, echo= TRUE , message=FALSE, warning=FALSE}
library(magrittr)
library(tidyverse)
library(car)
library(DescTools)

```



## Data:

The data consists of 42535 observations for  144 variables

```{r data}
data<-read.csv("LoanStats3a.csv")   # Reading Lending club data(2007-2015)

dim(data)
```

However, the columns after column no. 50 are fully empty and hence ignored in the data

```{r col remove}
train_data<-data[,c(1:50)]
dim(train_data)
```
The following operation gives details about data frame "train_data" in brief.
```{r}
str(train_data)
```
It can be observed from above that the variable corresponding the out come  'Loan_status '  is represented as Factor. The following gives more information about the particular variable which is the variable of primary interest to us.
```{r}
levels(factor(train_data$loan_status))
```
```{r}
Desc(train_data$loan_status, plotit = T)
```
 
We can club levels [1] and [2] to single level "Charged Off"
and levels [3] and [4] to single level "Fully Paid"
We could use the concept of piping (comes with the package magritt) to increase the readability of the code.
```{r}
train_data <- train_data %>% mutate(loan_status=str_replace(loan_status, "Does not meet the credit policy. Status:", ""))%>% 
filter(loan_status %in% c("Fully Paid","Charged Off"))
levels(factor(train_data$loan_status))
barplot(table(train_data$loan_status) , col = 'lightblue')
```
```{r}
state_by_value <-
train_data %>% group_by(addr_state) %>%
  summarise(value = sum(loan_amnt, na.rm=TRUE))

```

The variables which such as "int_rate" and "term"  that contain important numerical data are represented as factors which is not desirable. The below operation converts them into numeric,integer etc. accordingly.

```{r}
head(train_data$int_rate)
train_data <- train_data %>% mutate(int_rate=str_replace(int_rate, "%", "")) %>% mutate(int_rate= as.numeric(int_rate))
train_data <- train_data %>% mutate(term=str_replace(term, "months", "")) %>% mutate(term= as.integer(term))
train_data <- train_data %>% mutate(revol_util=str_replace(revol_util, "%", "")) %>% mutate(revol_util= as.integer(revol_util))
head(train_data$int_rate)

```
From the available explainatory variables, it is useful to compute the correlation properties of the dataset. This can be done in two ways. However the dataset needs to be completely free of categorical type variables to avoid NA's . 
```{r}
train_data_no_categorical<- train_data %>%select_if(function(col) {(is.numeric(col) | is.integer(col)) })
head(train_data_no_categorical)
```
Further, the columns with zero colSum  are considered redundant and dropped from the dataset

```{r}
train_data_finite_sum<-train_data_no_categorical %>% select(-c(which(colSums(train_data_no_categorical,na.rm = T)==0)))
data_f<-train_data_finite_sum
```
Also,  some of the variables that represent the past history of a borrower like "funded_amnt","funded_amnt_inv","total_pymnt_inv" which are not available to consider for the current loan applicant and hence removed from the data set.
```{r}
drops <- c("funded_amnt","funded_amnt_inv","total_pymnt_inv","total_pymnt" ,"total_rec_prncp","total_rec_int","total_rec_late_fee", "recoveries", "collection_recovery_fee" ,"last_pymnt_amnt" )  #because these variable values are not known at the time of loan request
data_f<-data_f[ , !(names(data_f) %in% drops)]
```

Correlation matrix is found by directly applying the "cor" function
```{r}
correlation<-cor(data_f,use="complete.obs")

```
It is observed that the correlation is high between the following pairs of variables:
1. loan_amnt and installment
2. term and int_rate
3. pub_rec and mths_since_last_record
4. total_acc and open_acc

To take the account of categorical variables and append it to existing data , we do the following

```{r}
data_ff<-train_data%>%select(loan_status,grade,emp_length,home_ownership,verification_status)
data_final<-cbind(data_f,data_ff)
data_final <- na.omit(data_final)
#data_final <- data_final %>%mutate(loan_status=as.factor(loan_status))
dim(data_final)
data_final <- data_final %>%mutate(loan_status=as.factor(loan_status))
```
The data is split into two categories training set and test set(to see models stability) in the ratio 1:2 respectively. 

```{r}
training <- data_final[sample(nrow(data_final)),][1:round(0.66*nrow(data_final)),]

testing <- data_final[sample(nrow(data_final)),][(round(0.66*nrow(data_final))+1):nrow(data_final),]

```
1. Training set(2/3)
```{r}
dim(training)
```

2. Test Set (1/3)
```{r}
dim(testing)
```

##Feature Selection:
The relative importance of each variable can be quantified by the AIC(Akaike's Information Criterion) . We start with null model and proceed to  considercextra variable at each stage based on the condition that the selected variable gives least increment in AIC in comparision with previous set of variables. This process is called Forward Selection. The step function is implemented as shown below.

```{r}
dim(data_final)
model.null = glm(loan_status ~ 1, data = training, family = binomial(link = "logit")) 
model.full = glm(loan_status ~ ., data = training, family = binomial(link = 'logit')) 
step(model.null, scope = list(upper= model.full), direction='both', test='Chisq', data= 'training')
```
The optimized combination of variables is as follows :
1. mths_since_last_record 
2. inq_last_6mths
3. loan_amnt
4. term
5. grade 
6. revol_bal
7. dti 
8. mths_since_last_delinq
9. emp_length
10. total_acc
11. pub_rec
12. delinq_2yr
13. revol_util


The model is represented below
```{r}
 final_model<-glm(formula = loan_status ~ grade + inq_last_6mths + loan_amnt + 
    revol_bal + emp_length + total_acc + mths_since_last_record + 
    pub_rec + int_rate + installment + delinq_2yrs + revol_util, 
    family = binomial(link = "logit"), data = data_final)
summary(final_model)
```
##Testing the Model on training data
```{r}

training_1=training
training_1$predicted_loan_status = predict(final_model, newdata=training_1,type = "response")
training_1 <- training_1 %>% mutate(predicted_loan_status = ifelse(predicted_loan_status < 0.5, "Charged Off","Fully Paid"))
confusion_matrix_1 <- table(training_1$predicted_loan_status, training_1$loan_status)
confusion_matrix_1
#dim(training_1)
#length(which(training_1$loan_status=="Fully Paid"))
#length(which(training_1$loan_status=="Charged Off"))
#length(training_1$loan_status)
```
Specificity

```{r}
specificity <- confusion_matrix_1[2,2]/(confusion_matrix_1[1,2]+confusion_matrix_1[2,2])
specificity

```
Sensitivity
```{r}
sensitivity <- confusion_matrix_1[1,1]/(confusion_matrix_1[2,1]+confusion_matrix_1[1,1])
sensitivity

```
Accuracy
```{r}
Accuracy <- (confusion_matrix_1[1,1]+confusion_matrix_1[2,2])/sum(confusion_matrix_1)
Accuracy
```

## Testing the model on Test data
```{r}
testing$predicted_loan_status = predict(final_model, newdata=testing,type = "response")
testing <- testing %>% mutate(predicted_loan_status = ifelse(predicted_loan_status < 0.5, "Charged Off","Fully Paid"))
confusion_matrix <- table(testing$predicted_loan_status, testing$loan_status)
confusion_matrix
#length(which(testing$loan_status=="Fully Paid"))
#length(which(testing$loan_status=="Charged Off"))
#length(testing$loan_status)

```
Accuracy
```{r}
Accuracy <- (confusion_matrix[1,1]+confusion_matrix[2,2])/sum(confusion_matrix)
Accuracy
```
##A Better Alternative Model : Decision Trees with Random Forests

In light of unsatisfactory results from logistic regression we move on to decision trees and random forests in particular and implement the model on the same set of data as defined  in above sections for implementing logistic regression.
```{r}
training_rf=training
library (randomForest) 
set.seed(1) 
bag.loan=randomForest(loan_status~.,data=training_rf, mtry=4,importance=TRUE) 
summary(bag.loan)

```
## Testing the Model
```{r}
training_rf$predicted_loan_status = predict(bag.loan, newdata=training_rf,type = "response")
confusion_matrix_rf <- table(training_rf$predicted_loan_status, training_rf$loan_status)
confusion_matrix_rf
```



Accuracy
```{r}
Accuracy <- (confusion_matrix_rf[1,1]+confusion_matrix_rf[2,2])/sum(confusion_matrix_rf)
Accuracy
```
Specificity

```{r}
specificity <- confusion_matrix_rf[2,2]/(confusion_matrix_rf[1,2]+confusion_matrix_rf[2,2])
specificity

```
Sensitivity
```{r}
sensitivity <- confusion_matrix_rf[1,1]/(confusion_matrix_rf[2,1]+confusion_matrix_rf[1,1])
sensitivity

```
## Testing the model with Test set
```{r}
testing_rf=testing
testing_rf$predicted_loan_status = predict(bag.loan, newdata=testing_rf,type = "response")
confusion_matrix_rf <- table(testing_rf$predicted_loan_status, testing_rf$loan_status)
confusion_matrix_rf

```
Specificity
```{r}
specificity <- confusion_matrix_rf[2,2]/(confusion_matrix_rf[1,2]+confusion_matrix_rf[2,2])
specificity
```
Sensitivity
```{r}
sensitivity <- confusion_matrix_rf[1,1]/(confusion_matrix_rf[2,1]+confusion_matrix_rf[1,1])
sensitivity
```

Accuracy
```{r}
Accuracy <- (confusion_matrix_rf[1,1]+confusion_matrix_rf[2,2])/sum(confusion_matrix_rf)
Accuracy
```
Sensitivity indicates the proportion correct of default prediction. Sensitivity being a critical variable to evaluate a model's performance has improved  a lot with decision trees compared to previous model using logistic regression.Accuracy also has significantly improved from 0.75 to 0.9.
